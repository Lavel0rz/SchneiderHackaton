{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf95e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "## Bucle para obtener los dataframes a traves de las api calls\n",
    "countryName = []\n",
    "eprtrSectorName = []\n",
    "EPRTRAnnexIMainActivityLabel = []\n",
    "FacilityInspireID = []\n",
    "facilityName = []\n",
    "City =[]\n",
    "targetRelease = []\n",
    "pollutant = []\n",
    "reportingYear = []\n",
    "MONTH= []\n",
    "DAY = []\n",
    "CONTINENT= []\n",
    "max_wind_speed =[]\n",
    "avg_wind_speed= []\n",
    "min_wind_speed = []\n",
    "max_temp = []\n",
    "avg_temp= []\n",
    "min_temp=[]\n",
    "FOGDAYS=[]\n",
    "CITYID = []\n",
    "\n",
    "\n",
    "url1 = 'http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/first'\n",
    "url2 = 'http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/second'\n",
    "url3 = 'http://schneiderapihack-env.eba-3ais9akk.us-east-2.elasticbeanstalk.com/third'\n",
    "urls = [url1,url2,url3]\n",
    "for url in urls: \n",
    "\n",
    "    from urllib.request import urlopen\n",
    "\n",
    "    # import json\n",
    "    import json\n",
    "    # store the URL in url as \n",
    "    # parameter for urlopen\n",
    "    url = url\n",
    "\n",
    "    # store the response of URL\n",
    "    response = urlopen(url)\n",
    "\n",
    "    # storing the JSON response \n",
    "    # from url in data\n",
    "    data_json = json.loads(response.read())\n",
    "\n",
    "    \n",
    "    for jsons in data_json:\n",
    "        countryName.append(jsons.get('countryName'))\n",
    "        eprtrSectorName.append(jsons.get('eprtrSectorName'))\n",
    "        EPRTRAnnexIMainActivityLabel.append(jsons.get('EPRTRAnnexIMainActivityLabel'))\n",
    "        FacilityInspireID.append(jsons.get('FacilityInspireID'))\n",
    "        facilityName.append(jsons.get('facilityName'))\n",
    "        City.append(jsons.get('City'))\n",
    "        targetRelease.append(jsons.get('targetRelease'))\n",
    "        pollutant.append(jsons.get('pollutant'))\n",
    "        reportingYear.append(jsons.get('reportingYear'))\n",
    "        MONTH.append(jsons.get('MONTH'))\n",
    "        DAY.append(jsons.get('DAY'))\n",
    "        CONTINENT.append(jsons.get('CONTINENT'))\n",
    "        max_wind_speed.append(jsons.get('max_wind_speed'))\n",
    "        avg_wind_speed.append(jsons.get('avg_wind_speed'))\n",
    "        min_wind_speed.append(jsons.get('min_wind_speed'))\n",
    "        max_temp.append(jsons.get('max_temp'))\n",
    "        avg_temp.append(jsons.get('avg_temp'))\n",
    "        min_temp.append(jsons.get('min_temp'))\n",
    "        FOGDAYS.append(jsons.get('DAY WITH FOGS'))\n",
    "        CITYID.append(jsons.get('CITY ID'))\n",
    "\n",
    "    \n",
    "df_json = pd.DataFrame({'countryName':countryName,\n",
    "                        'eprtrSectorName':eprtrSectorName,\n",
    "                        'EPRTRAnnexIMainActivityLabel':EPRTRAnnexIMainActivityLabel,\n",
    "                        'FacilityInspireID':FacilityInspireID,\n",
    "                        'facilityName':facilityName,\n",
    "                        'City':City,\n",
    "                        'targetRelease':targetRelease,\n",
    "                        'pollutant':pollutant,\n",
    "                        'reportingYear':reportingYear,\n",
    "                        'MONTH':MONTH,\n",
    "                        'DAY':DAY,\n",
    "                        'CONTINENT':CONTINENT,\n",
    "                        'max_wind_speed':max_wind_speed,\n",
    "                        'avg_wind_speed':avg_wind_speed,\n",
    "                        'min_wind_speed':min_wind_speed,\n",
    "                        'max_temp':max_temp,\n",
    "                        'avg_temp':avg_temp,\n",
    "                        'min_temp': min_temp,\n",
    "                        'FOGDAYS':FOGDAYS,\n",
    "                        'CITYID':CITYID})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779848f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json.rename(columns = {'FOGDAYS':'DAY WITH FOGS'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f26e5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r\"C:\\Users\\Usuario\\Desktop\\SchneiderHackaton\\train1.csv\")\n",
    "df2 = pd.read_csv(r\"C:\\Users\\Usuario\\Desktop\\SchneiderHackaton\\train2.csv\",sep=';')\n",
    "\n",
    "df_csv = pd.concat([df1,df2])\n",
    "df_total = pd.concat([df_csv,df_json])\n",
    "df_total.reset_index().drop('index',inplace =True,axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9120de12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Carbon dioxide (CO2)', 'Nitrogen oxides (NOX)', 'Methane (CH4)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total['pollutant'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d5b434cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapeamos el target \n",
    "\n",
    "dict_map ={'Carbon dioxide (CO2)':1,'Nitrogen oxides (NOX)':0,'Methane (CH4)':2}\n",
    "\n",
    "df_total['pollutant'] = df_total['pollutant'].map(dict_map)\n",
    "\n",
    "for columns in df_total.columns:\n",
    "    try:\n",
    "        df_total[columns]= df_total[columns].astype(float)\n",
    "    except:\n",
    "        'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035bdaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mas o menos de 5 dias de niebla\n",
    "def foggy(x):\n",
    "    if x >5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "df_total['FOGGY']= df_total['DAY WITH FOGS'].apply(foggy)\n",
    "#Es o no es el reino unido, donde parece que tiene una distribucion de pollutant muy distinta a los otros paises\n",
    "def isuk(x):\n",
    "    if x == 'United Kingdom':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "df_total['ISUK'] = df_total['countryName'].apply(isuk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8ad206ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = df_total.drop(columns = ['countryName','FacilityInspireID','facilityName','City','targetRelease','CONTINENT','eprtrSectorName'])\n",
    "df_proc = df_proc.drop(columns = ['CITY ID','REPORTER NAME','CITYID'])\n",
    "\n",
    "\n",
    "df_proc.drop(columns = ['DAY WITH FOGS','reportingYear','MONTH','DAY'],inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61505325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Averiguar por qu√© en x_test.csv no tenemos el mismo shape que en train\n",
    "train_not_test= df_dummed.columns.difference(dftest.columns)\n",
    "train_not_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860eeeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_dummed.drop('EPRTRAnnexIMainActivityLabel_Chemical installations for the production on an industrial scale of basic organic chemicals: Phosphorus-containing hydrocarbons',axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "81010f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e3c8ec7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6815642458100558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "X = df_dummed[df_dummed.columns[1:]]\n",
    "y = df_dummed['pollutant']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.15,\n",
    "                                                    random_state=2)\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=250)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ae719e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering, probamos nuevas variables numericas\n",
    "v= df_dummed[\"avg_wind_speed\"]\n",
    "t= df_dummed[\"avg_temp\"]\n",
    "df_dummed[\"Temp_Sen\"] = 13.12 + 0.6215 * t - 11.73 * v ** 0.16 + 0.3965 * t * v ** 0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32691a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "658df098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desviacion temp maxima\n",
    "df_dummed['var_max_temp'] = df_dummed.max_temp - df_dummed.avg_temp\n",
    "df_dummed['var_max_temp'] = df_dummed['var_max_temp'].apply(lambda x: ((x**2)/2)**0.5)\n",
    "\n",
    "# Desviacion tipica Temp min\n",
    "df_dummed['var_min_temp'] = df_dummed.min_temp - df_dummed.avg_temp\n",
    "df_dummed['var_min_temp'] = df_dummed['var_min_temp'].apply(lambda x: ((x**2)/2)**0.5)\n",
    "\n",
    "# Desviacion tipica viento max\n",
    "df_dummed['var_max_wind'] = df_dummed.max_wind_speed - df_dummed.avg_wind_speed\n",
    "df_dummed['var_max_wind'] = df_dummed['var_max_wind'].apply(lambda x: ((x**2)/2)**0.5)\n",
    "\n",
    "# Desviacion tipica viento min\n",
    "df_dummed['var_min_wind'] = df_dummed.min_wind_speed - df_dummed.avg_wind_speed\n",
    "df_dummed['var_min_wind'] = df_dummed['var_min_wind'].apply(lambda x: ((x**2)/2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438dfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "37ad1967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "486efc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest['pollutant']= clf.predict(dftest[dftest.columns[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f2f7eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest[['test_index','pollutant']].to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "{'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800]}\n",
    "\n",
    "''' # Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)'''\n",
    "\n",
    "# Grid search utilizado para saber cuales eran los mejores parametros.... tarda muchisimo en ejecutar y no gana tanta precision,\n",
    "#{'n_estimators': 1600, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 90, 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd4393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lectura pdfs \n",
    "def leer_pdf(ruta):\n",
    "\n",
    "    from pdfminer.high_level import extract_text\n",
    "    s = extract_text(ruta)\n",
    "    s = s.split('\\n')\n",
    "\n",
    "    ls_pdf = []\n",
    "    for i in s:\n",
    "        if i == '':\n",
    "            continue\n",
    "        else:\n",
    "            ls_pdf.append(i)\n",
    "\n",
    "    ls_def=[]\n",
    "    ls_def = ls_pdf[15:-4]\n",
    "    ls_new = [ls_def[1], ls_def[7], ls_def[15], ls_def[17], ls_def[19], ls_def[21], ls_def[22], ls_def[24]]\n",
    "    ls_new[2] = ls_new[2][16:]\n",
    "    ls_new.append(ls_new[7])\n",
    "    ls_new[7] = ls_new[6]\n",
    "    ls_new[6] = ls_new[5][:8]\n",
    "    ls_new[5]= ls_new[4]\n",
    "    ls_new[4]= ls_new[3][25:]\n",
    "    ls_new[3] = ls_new[3][:8]\n",
    "    return ls_new\n",
    "import os \n",
    "carpeta = os.listdir(\"train6\")\n",
    "ls_dire = []\n",
    "\n",
    "for i in carpeta:\n",
    "    i = \"train6\\\" + i\n",
    "    ls_dire += [i]\n",
    "\n",
    "ls_noentran = []\n",
    "ls_final = []\n",
    "for j in ls_dire:\n",
    "    try:\n",
    "        ls_final.append(leer_pdf(j))\n",
    "    except:\n",
    "        ls_noentran.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55ba7e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11206    2.0\n",
       "2393     0.0\n",
       "6098     0.0\n",
       "13933    2.0\n",
       "2257     0.0\n",
       "        ... \n",
       "25683    1.0\n",
       "5102     0.0\n",
       "9529     0.0\n",
       "4832     1.0\n",
       "23933    2.0\n",
       "Name: pollutant, Length: 9845, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Varianza temp maxima\n",
    "df_dummed['var_max_temp'] = df_dummed.max_temp - df_dummed.avg_temp\n",
    "df_dummed['var_max_temp'] = df_dummed['var_max_temp'].apply(lambda x: (x**2)/2)\n",
    "\n",
    "# Varianza Temp min\n",
    "df_dummed['var_min_temp'] = df_dummed.min_temp - df_dummed.avg_temp\n",
    "df_dummed['var_min_temp'] = df_dummed['var_min_temp'].apply(lambda x: (x**2)/2)\n",
    "\n",
    "#Varianza viento max\n",
    "df_dummed['var_max_wind'] = df_dummed.max_wind_speed - df_dummed.avg_wind_speed\n",
    "df_dummed['var_max_wind'] = df_dummed['var_max_wind'].apply(lambda x: (x**2)/2)\n",
    "\n",
    "#Varianza viento min\n",
    "df_dummed['var_min_wind'] = df_dummed.min_wind_speed - df_dummed.avg_wind_speed\n",
    "df_dummed['var_min_wind'] = df_dummed['var_min_wind'].apply(lambda x: (x**2)/2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3065c0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2690ac8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582ed48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38a501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b55ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854e335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e7c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf5168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c9660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5fdf51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37603f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ddb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8af143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6e5a247c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f56dcd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "24475    0\n",
       "24476    0\n",
       "24477    0\n",
       "24478    0\n",
       "24479    0\n",
       "Name: EPRTRAnnexIMainActivityLabel_Chemical installations for the production on an industrial scale of basic organic chemicals: Dyes and pigments, Length: 24480, dtype: uint8"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa19dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e32b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc51fb40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
